{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3444b21d-4204-48a6-a76c-0c7c36820630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e39094aa-6a4c-4513-953d-a050d5d3c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "original_dataframe = pd.read_csv('24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2ab687e5-3103-4ab0-b67d-20bd0ab510b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_outliers_iqr(df_orig):\n",
    "  df = df_orig.copy()\n",
    "\n",
    "  df_numeric = df.select_dtypes(include=['number']).select_dtypes(exclude=['bool'])\n",
    "  df_non_numeric = df.select_dtypes(exclude=['number'])\n",
    "\n",
    "  Q1 = df_numeric.quantile(0.25)\n",
    "  Q3 = df_numeric.quantile(0.75)\n",
    "  IQR = Q3 - Q1\n",
    "\n",
    "  lower_bound = Q1 - 1.5 * IQR\n",
    "  upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "  # Removing outliers\n",
    "  df_iqr = df_numeric[~((df_numeric < lower_bound) | (df_numeric > upper_bound)).any(axis=1)]\n",
    "  df_cleaned = pd.concat([df_iqr, df_non_numeric.loc[df_iqr.index]], axis=1)\n",
    "\n",
    "  return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bcfbd14-1288-4c9c-b1aa-b68049bbf3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_zscore(df_orig, z_score_threshold = 3):\n",
    "  df = df_orig.copy()\n",
    "\n",
    "  df_numeric = df.select_dtypes(include=['number']).select_dtypes(exclude=['bool'])\n",
    "  df_non_numeric = df.select_dtypes(exclude=['number'])\n",
    "\n",
    "  z_scores = df_numeric.apply(zscore)\n",
    "  df_z = df_numeric[(z_scores.abs() < z_score_threshold).all(axis=1)]  # Remove rows with Z-score >  z_score_threshold in any column\n",
    "  df_cleaned = pd.concat([df_z, df_non_numeric.loc[df_z.index]], axis=1)\n",
    "\n",
    "  return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bf6579b6-51e1-4130-8f28-67174c216072",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_highly_correlated(df_cleaned_orig, target_col=\"Hazardous\", high_corr_threshold = 0.99):\n",
    "  df_cleaned = df_cleaned_orig.copy()\n",
    "\n",
    "  df_numeric = df_cleaned.select_dtypes(include=['number']).select_dtypes(exclude=['bool'])\n",
    "\n",
    "  target_series = None\n",
    "  if target_col in df_numeric.columns: # High correaltion with target column should not be dropped\n",
    "    target_series = df_cleaned[target_col]\n",
    "    df_numeric = df_numeric.drop(columns=[target_col])\n",
    "\n",
    "  high_corr_pairs = set()\n",
    "  correlation_matrix = df_numeric.corr()\n",
    "\n",
    "  for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i): # Lower triangular matrix\n",
    "      if abs(correlation_matrix.iloc[i, j]) >= high_corr_threshold:\n",
    "        col1 = correlation_matrix.columns[i]\n",
    "        col2 = correlation_matrix.columns[j]\n",
    "        high_corr_pairs.add((col1, col2))\n",
    "\n",
    "  columns_to_drop = {col2 for col1, col2 in high_corr_pairs}\n",
    "  df_reduced = df_cleaned.drop(columns=columns_to_drop)\n",
    "\n",
    "  if target_series is not None: # If present in df_numeric and is removed, has to be added again\n",
    "    df_reduced[target_col] = target_series\n",
    "\n",
    "  return df_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6e48875-156b-4c96-9c05-0253dd86f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_minmax(df_train, df_test, df_valid):\n",
    "  scaler = MinMaxScaler()\n",
    "\n",
    "  df_train_numeric = df_train.select_dtypes(include=['number']).select_dtypes(exclude=['bool'])\n",
    "  df_test_numeric = df_test.select_dtypes(include=['number']).select_dtypes(exclude=['bool'])\n",
    "  df_valid_numeric = df_valid.select_dtypes(include=['number']).select_dtypes(exclude=['bool'])\n",
    "\n",
    "  df_train[df_train_numeric.columns] = scaler.fit_transform(df_train_numeric)\n",
    "  df_test[df_test_numeric.columns] = scaler.transform(df_test_numeric)\n",
    "  df_valid[df_valid_numeric.columns] = scaler.transform(df_valid_numeric)\n",
    "\n",
    "  return df_train, df_test, df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c9bc0d0-70f4-4811-acdb-bbb510ca3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def standardize_data(df_train, df_test, df_valid):\n",
    "  scaler = StandardScaler()\n",
    "\n",
    "  df_train_numeric = df_train.select_dtypes(include=['number']).select_dtypes(exclude=['bool'])\n",
    "  df_test_numeric = df_test.select_dtypes(include=['number']).select_dtypes(exclude=['bool'])\n",
    "  df_valid_numeric = df_valid.select_dtypes(include=['number']).select_dtypes(exclude=['bool'])\n",
    "\n",
    "  df_train[df_train_numeric.columns] = scaler.fit_transform(df_train_numeric)\n",
    "  df_test[df_test_numeric.columns] = scaler.transform(df_test_numeric)\n",
    "  df_valid[df_valid_numeric.columns] = scaler.transform(df_valid_numeric)\n",
    "\n",
    "  return df_train, df_test, df_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "81e72e6b-187f-430c-8722-627b661876c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def label_encode_categorical(df_normalized):\n",
    "  df_normalized_copy = df_normalized.copy()\n",
    "\n",
    "  categorical_cols = df_normalized_copy.select_dtypes(include=['object']).columns\n",
    "  label_encoder = LabelEncoder()\n",
    "\n",
    "  for col in categorical_cols:\n",
    "    df_normalized_copy[col] = label_encoder.fit_transform(df_normalized_copy[col])\n",
    "\n",
    "  return df_normalized_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b6dd457-3b62-4f7e-8473-29873177254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_high_corr_features(df_train, df_test, df_valid, target_col=\"Hazardous\", top_n=3):\n",
    "  df_train_numeric = df_train.select_dtypes(include=['number']).select_dtypes(exclude=['bool'])\n",
    "\n",
    "  # If target column is not in numerical form\n",
    "  if target_col not in df_train_numeric.columns:\n",
    "      raise ValueError(f\"Target column '{target_col}' must be numeric and present in the dataset.\")\n",
    "\n",
    "  corr_values = df_train_numeric.corr()[target_col].abs().sort_values(ascending=False)\n",
    "  selected_features = corr_values.drop(index=target_col).head(top_n).index.tolist()\n",
    "\n",
    "  # print(f\"Selected features based on correlation with '{target_col}': {selected_features}\")\n",
    "\n",
    "  return df_train[selected_features], df_test[selected_features], df_valid[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "caa5c28d-f39f-47ba-b007-9ff5b98cf3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_pca(df_train, df_test, df_valid, n_components=3):\n",
    "  pca = PCA(n_components=n_components)\n",
    "\n",
    "  df_train_numeric = df_train.select_dtypes(include=['number'])\n",
    "  df_test_numeric = df_test.select_dtypes(include=['number'])\n",
    "  df_valid_numeric = df_valid.select_dtypes(include=['number'])\n",
    "\n",
    "  pca.fit(df_train_numeric)\n",
    "  df_train_pca = pca.transform(df_train_numeric)\n",
    "  df_test_pca = pca.transform(df_test_numeric)\n",
    "  df_valid_pca = pca.transform(df_valid_numeric)\n",
    "\n",
    "  pca_columns = [f'PC{i+1}' for i in range(n_components)]\n",
    "  df_train_pca = pd.DataFrame(df_train_pca, columns=pca_columns)\n",
    "  df_test_pca = pd.DataFrame(df_test_pca, columns=pca_columns)\n",
    "  df_valid_pca = pd.DataFrame(df_valid_pca, columns=pca_columns)\n",
    "\n",
    "  return df_train_pca, df_test_pca, df_valid_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73e4c499-3a63-4a99-96e1-da402390e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_conversion(df_orig, one_hot_encode_month=False):\n",
    "  df = df_orig.copy()\n",
    "\n",
    "  # Dropping 'Equinox' and 'Orbiting Body'\n",
    "  df.drop(columns=['Equinox', 'Orbiting Body'], errors='ignore', inplace=True)\n",
    "\n",
    "  # Converting 'Close Approach Date' to datetime\n",
    "  df['Close Approach Date'] = pd.to_datetime(df['Close Approach Date'])\n",
    "  df['Close Approach Year'] = df['Close Approach Date'].dt.year\n",
    "  df['Close Approach Month'] = df['Close Approach Date'].dt.month\n",
    "\n",
    "\n",
    "\n",
    "  # Converting 'Epoch Date Close Approach' to datetime\n",
    "  df['Converted Date'] = df['Epoch Date Close Approach'].apply(\n",
    "    lambda x: datetime.utcfromtimestamp(x / 1000) if pd.notnull(x) else None\n",
    "  )\n",
    "\n",
    "  df['Epoch Close Approach Year'] = df['Converted Date'].dt.year\n",
    "  df['Epoch Close Approach Month'] = df['Converted Date'].dt.month\n",
    "\n",
    "\n",
    "\n",
    "  # Encoding 'Hazardous' column\n",
    "  df['Hazardous'] = df['Hazardous'].astype(int)\n",
    "\n",
    "  # One-Hot Encoding for months (if needed)\n",
    "  if one_hot_encode_month:\n",
    "    df = pd.get_dummies(df, columns=['Close Approach Month', 'Epoch Close Approach Month'], prefix=['Close Approach Month no.', 'Epoch Close Approach Month no.'], dtype=int)\n",
    "\n",
    "  df = df.drop(columns=[\"Converted Date\"])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94ba7c7e-1781-47fe-aca2-9c0d09e1dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_preprocessing(df):\n",
    "  no_outliers = remove_outliers_zscore(df)\n",
    "  no_highly_correlated = remove_highly_correlated(no_outliers)\n",
    "  encoded = numeric_conversion(no_highly_correlated)\n",
    "  df_train, df_temp = train_test_split(encoded, test_size=0.4, random_state=42)\n",
    "  df_valid, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)\n",
    "  normal_train, normal_test, normal_valid = normalize_minmax(df_train, df_test, df_valid)\n",
    "  normal_train.reset_index(drop=True, inplace=True)\n",
    "  normal_valid.reset_index(drop=True, inplace=True)\n",
    "  normal_test.reset_index(drop=True, inplace=True)\n",
    "  return normal_train, normal_valid, normal_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "06dc84b5-e91a-4075-b769-6229ba9b3de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lohit\\AppData\\Local\\Temp\\ipykernel_4608\\3347725585.py:16: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  lambda x: datetime.utcfromtimestamp(x / 1000) if pd.notnull(x) else None\n"
     ]
    }
   ],
   "source": [
    "normal_train, normal_valid, normal_test = data_preprocessing(original_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ae184266-e08f-4706-953a-fbc83e48bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"Hazardous\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d1061e4c-23a1-4a1d-a7bb-5458df32ea32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = normal_train.drop(columns=[target_column])\n",
    "y_train = normal_train[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "61b362b2-65ee-4aa5-a2e9-7a7a21f0b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_valid = normal_valid.drop(columns=[target_column])\n",
    "y_valid = normal_valid[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1bdf0b12-1199-4652-a98c-26c1bc9cd1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = normal_test.drop(columns=[target_column])\n",
    "y_test = normal_test[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3442d2fd-1826-4e49-82d3-ba2413ec32a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2512, 26)\n",
      "X_valid shape: (837, 26)\n",
      "X_test shape: (838, 26)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_valid shape:\", X_valid.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c73921e7-25ea-4b55-8eec-86cda8449a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5da0b2d0-82b1-4564-903d-67ad5cc36889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train[\"Close Approach Date\"] = X_train[\"Close Approach Date\"].astype(\"int64\") // 10**9  # Convert to seconds\n",
    "X_valid[\"Close Approach Date\"] = X_valid[\"Close Approach Date\"].astype(\"int64\") // 10**9\n",
    "X_test[\"Close Approach Date\"] = X_test[\"Close Approach Date\"].astype(\"int64\") // 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e054d098-ca87-4030-ae74-8b08544741de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train[\"Orbit Determination Date\"] = pd.to_datetime(X_train[\"Orbit Determination Date\"]).astype(\"int64\") // 10**9\n",
    "X_valid[\"Orbit Determination Date\"] = pd.to_datetime(X_valid[\"Orbit Determination Date\"]).astype(\"int64\") // 10**9\n",
    "X_test[\"Orbit Determination Date\"] = pd.to_datetime(X_test[\"Orbit Determination Date\"]).astype(\"int64\") // 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b9c077de-e346-46ba-944e-0e14ed110c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Metrics:\n",
      "Confusion Matrix:\n",
      "[[722   0]\n",
      " [116   0]]\n",
      "Accuracy: 0.8616\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "\n",
      "\n",
      "Validation Data Metrics:\n",
      "Confusion Matrix:\n",
      "[[682   0]\n",
      " [155   0]]\n",
      "Accuracy: 0.8148\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lohit\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lohit\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "logistic_reg = LogisticRegression(solver='sag',max_iter=10000)\n",
    "logistic_reg.fit(X_train,y_train)\n",
    "y_val_pred = logistic_reg.predict(X_valid)\n",
    "y_test_pred = logistic_reg.predict(X_test)\n",
    "#For test\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Data Metrics:\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"\\n\")\n",
    "#For val\n",
    "accuracy = accuracy_score(y_valid, y_val_pred)\n",
    "precision = precision_score(y_valid, y_val_pred)\n",
    "recall = recall_score(y_valid, y_val_pred)\n",
    "f1 = f1_score(y_valid, y_val_pred)\n",
    "conf_matrix = confusion_matrix(y_valid, y_val_pred)\n",
    "\n",
    "print(f\"Validation Data Metrics:\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f586bb-d5f4-458c-b201-5409e7858b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
